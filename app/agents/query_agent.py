# ğŸ”¹ app/agents/query_agent.py

from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

llm = ChatOpenAI(temperature=0.7, model="gpt-3.5-turbo")

def generate_inferred_paper(topic: str, references: list[str]) -> str:
    joined_refs = "\n".join(references)
    prompt = ChatPromptTemplate.from_template("""
ë„ˆëŠ” ê³¼í•™ ë…¼ë¬¸ ì‘ì„± ë„ìš°ë¯¸ì•¼.

ì£¼ì œ: {topic}
ì°¸ê³  ë…¼ë¬¸:
{references}

ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ ë…¼ë¬¸ì„ ì‘ì„±í•´ì¤˜:
[ì„œë¡ ] [ë¬¸ì œì •ì˜] [ì—°êµ¬ëª©ì ] [ì‹¤í—˜ë°©ë²•] [ê²°ê³¼ì˜ˆìƒ] [ê²°ë¡ ]
""")
    chain = prompt | llm
    return chain.invoke({"topic": topic, "references": joined_refs}).content
